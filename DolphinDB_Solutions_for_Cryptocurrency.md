# DolphinDB 数字货币解决方案
在金融领域, 数字货币交易正在快速兴起。在行情数据存储和处理方面，数字货币既有传统金融行情的典型特征，也有自己新的特点。

本文将介绍使用 DolphinDB 处理数字货币海量数据的解决方案。

- [DolphinDB 数字货币解决方案](#dolphindb-数字货币解决方案)
  - [1 概述](#1-概述)
  - [2 海量数据存储](#2-海量数据存储)
    - [2.1 分布式数据库](#21-分布式数据库)
      - [2.1.1 数据分区](#211-数据分区)
      - [2.1.2 数据建表](#212-数据建表)
    - [2.2 数字货币的数据特征](#22-数字货币的数据特征)
    - [2.3 历史数据导入](#23-历史数据导入)
    - [2.4 分级存储](#24-分级存储)
    - [2.5 数据压缩](#25-数据压缩)
    - [2.6 数据点查询](#26-数据点查询)
    - [2.7 多模数据库（时序建模 + 关系建模）](#27-多模数据库时序建模--关系建模)
    - [2.8 co-location 存储](#28-co-location-存储)
    - [2.9 宽表存储](#29-宽表存储)
  - [3 数据读写接口](#3-数据读写接口)
    - [3.1 API](#31-api)
    - [3.2 插件系统](#32-插件系统)
  - [4 历史数据分析](#4-历史数据分析)
    - [4.1 K 线计算](#41-k-线计算)
    - [4.2 指标计算](#42-指标计算)
      - [4.2.1  SQL 模式](#421--sql-模式)
      - [4.2.2 面板模式](#422-面板模式)
  - [5.	实时数据处理](#5实时数据处理)
    - [5.1、实时数据接入](#51实时数据接入)
    - [5.2、实时数据计算](#52实时数据计算)
    - [5.3、实时数据计算结果输出](#53实时数据计算结果输出)
    - [5.4、数据回放](#54数据回放)
    - [5.5、批流一体](#55批流一体)
  - [6. 高可用方案](#6-高可用方案)
    - [6.1、高可用概述](#61高可用概述)
    - [6.2、元数据高可用](#62元数据高可用)
    - [6.3、数据高可用](#63数据高可用)
    - [6.4、流数据高可用](#64流数据高可用)
    - [6.5、客户端高可用](#65客户端高可用)
  - [7.	小结](#7小结)
## 1 概述
相较于传统金融，数字货币的场景特征如下：

- 数字货币的行情数据增量很大，金融股票数据日增数据量几十 GB，而数字货币的日增数据目前超过 10TB，后续还会持续增长。
- 数字货币市场 7*24 小时不间断交易。
- 行情发布频率更高。
- 币种之间的数据量不平衡，头部货币的行情数据量占据了绝大部分比重。
- 不同币种盘口行情数据的深度千差万别，少至 10 档，多至 1000 档之上。
- 行情波动迅速，并且幅度巨大，实时计算及系统对接的延时非常敏感。




DolphinDB 作为分布式时序数据库 , 非常适合数字货币海量数据存储和计算需求。DolphinDB 内置分布式多模数据库、支持灵活的数据分区机制，支持库内实时流式计算，能够为海量时间序列数据的快速存储、检索、历史分析及实时计算提供一站式解决方案。
DolphinDB 的功能架构图见图 1-1：

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/architecture.png width=40%>

图 1-1
</div>

相较于其他通用型大数据存储和计算方案，DolphinDB 对数字货币在内的金融行业的存储和计算需求做了大量功能适配和性能优化，具有架构成熟、适配性强、开发敏捷的特点。DolphinDB 采用三位一体的融合设计架构，强调数据库、编程语言和分布式计算三者的融合。这突出了数字时代用户对数据挖掘的需求。
DolphinDB 的设计架构图见图 1-2：


<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/design.png width=25%>

图 1-2
</div>


DolphinDB 拥有完整的流式计算框架，提供了多种流计算引擎。使用工程化低代码参数配置的方式，能够高效快速完成数字货币的实时业务开发。相比传统的流计算框架，DolphinDB 可节省 90% 以上的开发工作量。并且案例越复杂，DolphinDB 的优势越明显。流计算内部使用 C++ 实现了增量计算的算法，可以显著缩短计算的延时。支持共享内存、插件、API 等多种方式把计算结果快速提供给交易风控等系统。

## 2 海量数据存储
数字货币交易所的首要需求是把日增超过10TB，总量超过PB级的数据存储下来，并且能够支持高效查询和分析。传统的关系型数据库面对这个体量的数据完全束手无策。一些时序数据库尽管能够存储这个量级的数据，但是在数字货币及金融领域使用数据的场景上支持力度不足，概述章节中提及的数字货币及金融场景的典型需求无法覆盖，导致后续的使用事倍功半。
。
DolphinDB 的存储引擎主要是针对金融场景设计的。不但全面覆盖了概述章节中提及的所有金融场景的需求，还针对数字货币场景的特殊性做了如下赋能：
- 采用分布式存储架构，支持在线横向扩展，完全能容纳数字货币的庞大数据量，并且考虑到海量数据的快速检索，DolphinDB采用了分区方式规划数据，良好的分区机制使得整体的数据量增长对查询的速度影响微乎其微，在几千亿数据表中，点查普通报价数据耗时个位毫秒，点查询报价深度 100 档的订单簿数据，耗时 20ms 左右。
- 提供多种分区方案，且支持多维度组合分区，这种灵活的分区方式，有效解决各币种之间数据量不平衡的问题。
- 对于海量历史数据入库，支持 NPZ、NPY、CSV、HDF5、Parquet、二进制文件格式，使用 DolpihnDB 的脚本可以直接读取入库，无需使用其它语言解析。
- 针对不同档位数共存的报价数据集，DolphinDB的ARRAY VECTOR数据类型可以支持单字段保存向量类型，并且支持不同币种报价档位不同的场景。这种设计，无需将报价数据按最大报价深度展开，减少了运维工作，同时没有空间浪费，并且压缩率更高。


### 2.1 分布式数据库
DolphinDB 有一个内置多模态高性能存储引擎的分布式数据库，支持布署数百个节点和数千个 CPU 核以上的集群，节点支持水平和垂直拓展，灵活性强。同时，它集成了功能强大的编程语言和数据分析系统，为海量结构化数据的快速存储、检索、分析及计算提供一站式解决方案。
DolphinDB 将各个节点的存储空间交给内置的分布式文件系统（DFS）统一进行管理，分区的规则与分区的存储位置解耦，数据分割不再按水平和垂直两个步骤进行，而是进行全局优化。这样一来，分区的粒度更细更均匀，在查询计算时能充分的利用整个集群的硬件资源。
DolphinDB 的 TSDB 引擎非常适合数字货币的场景，它使典型的 LSMT 的架构，支持存储数组向量（array vector），支持在创建数据库表时指定排序字段，同一个排序字段对应的数据在一个分区内部按顺序紧密排列在一起。排序字段可以和分区字段不同，无论是使用分区字段查询，还是使用排序字段查询，效率都非常高。TSDB 还支持对排序字段对应的数据去重，在建表时通过参数指定，即可保证在数据存储或更新时自动去重。

#### 2.1.1 数据分区
数据分区的基本思想是对大数据集采用分而治之的策略，将其划分为多个相对较小的数据集，非常适合处理数字货币的海量数据。DolphinDB 支持最多三个维度的分区，并提供了灵活的分区机制，包括值分区，范围分区，列表分区，哈希分区和组合分区。对于数字货币场景，由于数据量非常大，一般先用小时做一层值分区，再用代码做一层 hash 分区或范围分区，这样的分区方式可以保证一个分区的数据量大概在 200MB 到 2G 左右，并且各个分区之间大小比较均匀，可以解决头部货币的数据量比重大的问题。DolphinDB 的建库函数是 [database](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/d/database.html?highlight=database)，如下是针对数字货币场景建立分布式数据库的代码，分区是两层，第一层是小时值分区，第二层是 symbol hash 分区，用参数 engine 指定了 TSDB 引擎。

```
dbDate = database("", VALUE, datehour(2021.11.30T01:00:00)..datehour(2021.12.02T01:00:00))
dbSymbol = database("", HASH, [SYMBOL, 100])
db_database = database(directory="dfs://npz_orderbook",partitionType=COMPO,partitionScheme = [dbDate, dbSymbol],engine=`TSDB)
```
#### 2.1.2 数据建表
数据库建立完成之后，调用函数 [createPartitionedTable](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/c/createPartitionedTable.html?highlight=createpartitionedtable) 即可完成数据表的建立，通过参数 sortColumns 可以指定分区内的排序字段。系统默认 sortColumns 最后一列为时间列，其余列字段组合为 sortKey，同一个 sortKey 对应的数据将按时间列顺序连续存放在一起。查询时， 若查询条件包含 sortKey 列，可以快速定位数据所在的位置，提高查询性能。sortColumns 是每个分区内部 level file 内数据的排序依据，与其是否为分区字段无关。keepDuplicates 这个参数可以用来指定入库时，处理重复 sortColumns 数据的策略，默认值为 ALL，即保留所有数据。若设置为 FIRST，则保留重复数据中第一条写入到数据库中的数据；若设置为 LAST，则保留重复数据中最新的一条写入到数据库的数据。如下是订单簿数据表的建表语句：
```
db_database.createPartitionedTable(table=schemaTable,tableName=`orderbook,partitionColumns=`provider_timestamp`symbol,sortColumns=`exchange`symbol`contract_type`timestamp,keepDuplicates=LAST)`
```

### 2.2 数字货币的数据特征
对于数字货币，数据一般包括订单簿数据、逐笔数据和成交数据。成交数据和逐笔数据与传统的证券数据类似，使用二维表的方式即可存储。而订单簿数据比较特殊，它的基本字段如下：
```
symbol,exchange,contract_type,timestamp,asks_price,bids_price,asks_size,bids_size,asks_size_in_coin,bids_size_in_coin
```
在这些字段中 asks_price,bids_price,asks_size,bids_size,asks_size_in_coin,bids_size_in_coin 都会包含多档报价，对于一个特定的交易所的某一个币种而言，每一个字段都包含多列，从数据结构上来看，很像是一个矩阵。
对不同交易所的不同币种的而言，由于支持的报价深度千差万别，导致了一个字段包含的列数，也就是矩阵的宽度会有很大的区别。
目前报价深度小的只有 10 左右，大的已经超过了 1000。在传统的结构化存储时，必须把数据按最大深度展开，如此以来只有 10 档的数据也会被展开为 1000 多档，这就造成了空间的极大浪费。
而使用自由结构或非结构化的存储，数据间的对齐又会有很大的问题，计算速度与表关联效率都会非常差。
DolphinDB 提供了存储数组向量（array vector）的功能，能够把不定长的数组向量（array vector）存为一列，这就非常完美的解决了不同币种之间报价深度差别非常大的问题。
DolphinDB 中的数组向量 (array vector) 是一种列类型，用于在数据表中存储可变长度的数组。数据表可以把数据类型相同且含义相近的多列存为一列，这就天然适合了数字货币不同币种之间报价深度差别非常大的场景。这种存储方式可显著简化某些常用的查询与计算，亦可提高数据压缩比，提升查询速度。简单使用数字下标，就可以选取对应档位的数据，几十个 row 系列函数可以对数组向量 (array vector) 做横向计算，如 rowAvg，rowMax，rowSum 等。这些函数都可以方便的使用在 SQL 语句中，和单列数据的使用没有任何区别。
图 2-1 展示了数组向量 (array vector) 在数据表中的基本存储结构：

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/array_vector.png vector.png width=50%>

图 2-1
</div>

从图表中可以看到 3 个币种 DOGE,BTC 和 HOT 的报价深度分别为 2，4，3 的数组向量（array vector），保存在了 bids 和 asks 两列之中。

### 2.3 历史数据导入
针对数字货币的海量数据，DolphinDB 不但支持多种方式的历史数据入库，而且还提供便捷高效的作业管理。通过作业管理并行写入数据，能够充分使用集群的全部硬件性能。历史数据支持通过插件或函数的方式从文件或其它数据库导入 DolphinDB。针对数字货币场景，文件一般是存储为 CSV，NPZ/NPY 或 HDF5 格式，如前文所述，订单簿数据的多个档位需要存储为数组向量 (array vector)。[loadText](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/l/loadText.html?highlight=loadtext)、[ploadText](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/p/ploadText.html?highlight=ploadtext) 和 [loadTextEx](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/l/loadTextEx.html?highlight=loadtextex) 函数用于导入 CSV 文件。它们都有一个 arrayDelimiter 的参数，它的作用是指定数据文件中数组向量列的分隔符，默认是逗号。当文件按如下图 2-2 格式存储时，可以直接用函数导入为数组向量 (array vector)。

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/csv.png width=50%>

图 2-2</div>

如果已有的 csv 文件是传统的按列展开的模式，只需先把文件导入内存，然后在内存中使用 [fixedLengthArrayVector](https://www.dolphindb.cn/cn/help/200/FunctionsandCommands/FunctionReferences/f/fixedLengthArrayVector.html?highlight=fixedlengtharrayvector) 函数把多列合并为一个数组向量 (array vector) 即可。loadNpz 和 loadNpy 用于导入 NPZ 和 NPY 格式的文件，最大支持三维的 numpy array 对象，和 DolphinDB 的对象对照见图 2-3：

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/npz.png width=20%>

图 2-3</div>

存储为 npz/npy 格式的数字货币的订单簿数据，导入到 DolphinDB 的结构是字典，通过对字典的解析，生成包含数组向量 (array vector) 的内存表。然后使用 append! 函数，即可把内存表的数据写入前面定义的好分布式数据表中。DolphinDB 的 [HDF5 插件](https://gitee.com/dolphindb/DolphinDBPlugin/tree/master/hdf5) 支持把 HDF5 格式的数据导入数据库。DolphinDB 还提供了多种插件从其它数据库中来同步数据，比如 ODBC,mysql 等。
### 2.4 分级存储
由于数字货币的数据量非常巨大，硬盘空间非常容易成为瓶颈。 特别是当用户在云上部署时，更会遇到硬盘空间的限制。目前亚马逊云的单块硬盘容量上限为 16TB。即使配置 20 块硬盘，对于日增超过 10TB 的数据量而言，也是九牛一毛。DolphinDB 的分级存储功能就很好的解决了这个问题，对于近期常用数据会存储在集群的硬盘上，而比较久远的数据，通过参数配置的方式，自动迁移到 S3 上。这种存储对查询和计算是完全透明的，查询与计算的 SQL 语句与不分级时保持一致。
### 2.5 数据压缩
 DolphinDB 采用了 LZ4 和 Delta of delta 等无损压缩算法，对列式储存的数据进行快速压缩，并且支持对不同的数据类型的列采用不同压缩算法。对于重复度高的字符串类型，比如币种代码，交易所，商品类型等信息，可以改用 SYMBOL 类型。DolphinDB 的 SYMBOL 类型在压缩之前，会使用字典编码，将字符串转化成整型。因此，每个字符串只占用 4 个字节，可以显著减少字符串的存储空间。数字货币的订单簿数据使用数组向量 (array vector) 存储，数组向量 (array vector) 在底层存储时，首先把所有行的数据首尾相接存成一个连续数组，然后用另一个索引数组标记各行的位置。在压缩时，对连续数组的数据进行整体处理，使得压缩率更高。DolphinDB 存储数字货币订单簿数据时，根据档位深度的不同，压缩率可达 1:9 ~ 1:30 左右。
### 2.6 数据点查询
数字货币的币种非常多，数据量非常大。在大量数据集中点查少量数据是数字货币业务常用的场景。DolhpinDB 的 TSDB 引擎，拥有良好的分区机制和分区内的数据排序机制，点查询效率非常高，并且数据总数量的增加对点查询速度的影响微乎其微。下表是一个测试结果展示，测试的数据集包含一年的 orderbook 数据和 trade 数据，数据条数分别是 400 亿和 700 亿左右，orderbook 数据的报价深度是 100 档。每个用例都测试 100 次，结果取平均值。


| 查询内容 | 数据集 | 耗时 |
| :------ | :------ | :------ |
| 一条数据 | trade | 2.91ms |
| 一条数据 | orderbook | 15.98ms |
| 一个币种一天数据 | trade | 5.04ms |
| 一个币种一天数据 | orderbook | 188.79ms |

### 2.7 多模数据库（时序建模 + 关系建模）
除需支持时序模型外，数字货币业务还需要支持关系模型。时序模型主要存储如订单簿、订单、委托和指标因子等具有时序特征的大数据；在实际业务中，如计算期权面值需要用到合约乘数，又比如对组合需要根据交易所分类进行估值、因子、归因和风险计算，这些场景都是典型的关系模型。
DolphinDB 是一个多模数据库，同时支持时序数据模型和关系数据模型。支持 as of join, window join, cross join, equal join, full join, inner join, left join 和 prefix join 等多种数据关联方式。时序模型支持非同步关联，关系模型支持等值关联。

### 2.8 co-location 存储
在数字货币使用数据时，通常需要多表关联，用于微观结构分析、因子生成和交易策略。DolphinDB 的 co-location 存储架构会强行将同一分区的多个表存储在同一数据节点中，在关联计算时只需要读取同一节点数据，这样的存储架构可以避免节点间的数据传输，大幅提高关联查询速度。由于数字货币的数据量非常巨大，如果没有 co-location 存储机制，多表关联时，非常容易把集群的网络跑满，使得网络成为瓶颈，处理时间显著增加。

### 2.9 宽表存储
横截面计算在时序数据处理中极为常见，数字货币及金融场景中经常需要存储多个标的甚至全部标的在同一横截面上的因子，并且需要对横截面进行面板数据分析。宽表存储天然适合面板数据，并能减少数据冗余，提高查询速度。一部分时序数据库不支持大宽表或者存在明显的性能问题。DolphinDB 支持 32767 列大宽表，自研的 TSDB 存储引擎能够保证大宽表下的高性能读写。

## 3 数据读写接口
DolphinDB 提供各种语言的SDK来访问DolphinDB，如C++, Java, C#, Javascript ,  其中也包含数字货币领域最常用的编程技术栈Golang和Python。并且DolphinDB也支持以动态插件的方式支持接入盘中数据，比如通过kafka插件将实时数据接入到DolphinDB并落库。

### 3.1 API
DolphinDB 提供了 C++,GoLang, Python, Java, C#, Node.js, R 等语言 API。API 通过网络链接的方式与 DolphinDB 通信的。DolphinDB 的 API 有如下特点：
- API 支持高可用，API 能够在目标节点宕机的情况下，自动找到集群中任意一个可连接的节点，继续运行，保障业务的持续运转。
- 支持批量异步或并行写入数据。
- 提供了丰富的二次编程接口。
- DolphinDB 对各语言 API 数据类型的转换做了良好的支持，各语言 API 的读取数据后，有合适的数据结构直接使用。
- API 在查询数据时，支持压缩传输，这对数字货币大量数据的查询非常友好，压缩传输可以显著降低传输时间，提高查询速度。
- 支持通过 SSL 方式来保障信息传输的安全性。
- API 客户端支持订阅或写入流数据的功能，不但可以处理历史数据，也可以处理实时数据。

在数字货币的大数据量场景下，DolphinDB 的 server 和 API 为这些场景做了适配，使用方便，性能优异，详细的性能数据见 [DolphinDB API 性能基准测试报告](https://gitee.com/dolphindb/Tutorials_CN/blob/master/api_performance.md)

Python 语言非常适合大数据分析，通过压缩传输，Python API 可以从 DolphinDB 中快速提取数据。以从亚马逊云上取数据到本地为例，使用 Python API 查询 5GB orderbook 数据，开启压缩传输后，整体查询时间有 14 倍的提升。在支持快速读取数据的同时，Python API 也做了非常完备的数据结构的转换。既可以使用 ToDF 函数转化为 pandas 的 DataFrame 对象，也可以使用 ToList 函数转化为 list 对象。把订单簿转化为 list 对象之后，每一列的数组向量对应一个 numpy 的二维数组，非常方便使用。

### 3.2 插件系统
数字货币与 IT 技术结合非常紧密，在接口及模型方面有很多自研需求，这些需求与数据库密切配合，需要快速的读写数据。DolphinDB 支持动态加载外部插件，以扩展系统功能。插件和 DolphinDB 运行在同一个进程内，数据直接在内存中交互，相比网络，读写速度有 2~3 个数量级的提升。DolphinDB 已经开发提供了丰富的插件，涉及历史数据导入，实时数据导入，消息队列对接等。此外，DolphinDB 还支持自定义插件的开发，私有的接口及模型能够以插件的形式在 DolphinDB 中运行。数字货币的行情波动非常快，响应时延要求高，通过插件的方式与 DolphinDB 交互，不但可以做到和 C++ 相同的处理速度，而且使用 DolphinDB 的脚本语言进行业务开发，可以节省 90% 的开发工作量，显著提升开发效率，降低开发成本，极大缩减开发到生产的周期。

## 4 历史数据分析
在数字货币乃至整个金融领域，仅仅满足大量数据的存储与快速查询是远远不够的。更重要的是，让数据快速、高效、低成本地产生价值。这就涉及到了历史数据分析，目前绝大多数传统数据库的数据分析能力很弱，无法在库内满足数字货币领域复杂数据分析的需求。所以，传统方法在进行业务研究时，要先从数据库内提取数据，通过网络发送到一台中心服务器。在中心服务器上，使用分析型语言，一般是 Python 或 R，对数据进行研究分析。分析完成后，再经由网络把结果写回数据库或应用于生。面对数字货币日增超过 10TB、总量超过 PB 级的数据量，这种方法就会存在很多问题：

  - 数据传输会耗费大量时间，有时远超业务运算的耗时。
  - 中心化计算，无法使用整个集群的算力。
  - 中心服务器的负载太高，成本也太高。
  - 传统分析性语言的速度太慢。

DolphinDB 把分布式数据库，分布式计算及编程语言等功能融为一体。不但有强大的存储查询能力，还能够在 PB 级的数据量级下，满足数字或历史数据分析的需求。
DolphinDB 的分析计算有如下特点：
- DolphinDB 设计了大数据处理脚本编程语言。这种编程语言从流行的 Python 和 SQL 语言汲取了灵感，它的语法与 SQL 和 Python 非常相似，易于学习。它支持多范式编程，包括命令式编程、向量化编程、函数化编程、SQL 编程、RPC 编程以及元编程，表达能力非常强，代码十分简洁。同样的功能，实现起来比 Python 还简洁优雅，速度和 C++ 接近。
- 分布式的计算框架与分布式数据库相融合，实现了库内计算，避免了大量数据的迁移，充分使用了整个集群的资源。
- 内置流水线、map-reduce 和迭代计算等多种计算框架，显著简化模型设计的复杂度。
- 拥有强大并且可灵活管理的并行处理能力。
- DolphinDB 支持数十种复杂的滑动、滚动和累计窗口计算函数。支持均值、最大、最小、中间值等较为简单的窗口计算；也支持最小二乘数估计、person 相关性、协方差、标准差、移动加权平均等较为复杂的函数。满足技术指标中的各类复杂计算。
- DolphinDB 提供 asof join 和 window join 不等值关联的需求。在数字货币分析中，委托、、成交和订单簿等数据在计算时经常需要按标的和时间进行关联。当按时间关联时，通常两个表中的时间不是相等的，而是满足某种关系，譬如最近的一条记录，某个时间窗口内的记录等。这种不等值的关联，通过 DolphinDB 提供的 asof join 和 window join 能够简洁高效的实现。
- 内置 1000 多个金融领域使用的函数，并做了极致的优化。
- 支持向量化、矩阵化的计算。
- 支持分布式机器学习。

下面结合一些具体例子，展示一下 DolphinDB 基于数字货币历史数据的分析能力。
### 4.1 K 线计算
K 线计算是金融领域最常用的计算需求，我们通常需要将 tick 级别数据汇合成快照级、分钟级、日级等低频的数据。在数字货币领域，tick 数据尤其巨大，日内的 tick 数据要以 T 为单位来计算，这就对 K 线合成提出非常高的性能要求。在这个数据量级下选择分布式存储几乎是必然的选择，与此同时进行分布式计算充分利用多节点服务器资源亦是优先考虑。
传统的解决方案是选择一种分布式存储 (HDFS、HBASE、MongoDB、Kafka) 然后结合一款分布式计算平台 (Spark、Storm、link) 来组合使用，或者通过 Python 或者 C++ 来自行开发分布式计算框架进行 K 线计算。通过组合分布式存储和计算平台的方式，通常要搭建三个以上分布式集群，对服务器资源要求较高，同时为保证多种技术兼容的稳定性，对于运维人员的技术能力要求也比较高。而 DolphinDB 天然一体的分布式存储与分布式计算平台则很好的解决了这个问题，
通过一个简单的 SQL 语句即可分布式的完成 K 线计算。

```
trade=loadTable("dfs://currency", "trade")
minuteCoins = select  exchange, contract_type, symbol, time, minute, first(price) as open, max(price) as high,min(price) as low, last(price) as close, sum(size) as vol from trade group by exchange, contract_type, symbol,date(timestamp) as time, minute(timestamp) as minute
```
以这段代码为例，我们可以主动声明进行分布式的分钟级 K 线计算。对高频的 60 亿条的 tick 级数据合成 6000 万的分钟 K 数据耗时不超过 30 秒。

### 4.2 指标计算
根据指标的类型和使用者的习惯不同，DolphinDB 提供了面板和 SQL 两种计算方式。
在 SQL 模式中，自定义函数的参数一般为向量（列），输出一般为向量。指标函数的粒度尽可能小，只包含计算单个指标的业务逻辑，也不用考虑并行计算加速等问题;
在面板计算中，自定义函数的参数一般为向量，矩阵或表，输出一般为向量，矩阵或表。

#### 4.2.1  SQL 模式
DolphinDB 在存储和计算框架上都是基于列式结构，表中的一个列可以直接作为一个向量化函数的输入参数。
因此如果一个指标的计算逻辑只涉及股票自身的时间序列数据，不涉及多个数字货币横截面上的信息，可以直接在 SQL 中按数字货币分组，
然后在 select 中调用指标函数计算每个股票在一段时间内的指标值。如果数据在数据库中本身是按数字货币分区存储的，那么可以非常高效的实现数据库内并行计算。
```
def sum_diff(x, y){
    return (x-y)\(x+y)
}
def factorDoubleEMA(price){
    ema_20 = ema(price, 20)
    ema_40 = ema(price, 40)
    sum_diff_1000 = 1000 * sum_diff(ema_20, ema_40)
    return ema(sum_diff_1000,10) - ema(sum_diff_1000, 20)
}
select  exchange,contract_type,symbol,timestamp, `doubleEMA as factorname,factorDoubleEMA(price) as value from trade where timestamp between 2021.12.01T00:00:00.000012506 : 2021.12.01T00:00:10.000012506  context by exchange,contract_type,symbol
```
在上面的例子中，我们定义了一个因子函数 factorDoubleEMA，只需要用到数字货币的价格序列信息。
我们在 SQL 中通过 context by 子句按数字货币代码分组，然后调用 factorDoubleEMA 函数，计算每个数字货币的指标序列。
值得注意的是，context by 是 DolphinDB SQL 对 group by 的扩展。group by 只适用于聚合计算，也就是说输入长度为 n，输出长度是 1。
context by 适用于向量计算，输入长度是 n，输出长度也是 n。
另外因子函数 factorDOubleEMA 除了可以接受一个向量作为输入
，也可以接受一个面板数据作为输入。所以，只要因子函数的粒度尽可能细，就可以应用于很多场景。

#### 4.2.2 面板模式
面板数据 (panel data) 是以时间为索引，标的为列，指标作为内容的一种数据载体，它非常适用于以标的集合为单位的指标计算。将数据以面板作为载体，可以大大简化脚本的复杂度，通常最后的计算表达式可以从原始的数学公式中一对一的翻译过来。除此之外，可以充分利用 DolphinDB 矩阵计算的高性能。

在指标计算中，面板数据通常可以通过 panel 函数，或者 exec 搭配 pivot by 得到，具体样例如下表：每一行是一个时间点，每一列是一个数字货币。


| Timestamp|btusdt|ethusdt|shibustdt|sandusdt|...|
| :-----| :-----| ----: | ----: |----: |----: |
|2020.01.02T09:29:00.000|  266.3|12.9  |57.5| 24.0 |...|
|2020.01.02T09:30:00.000|  270.2|17.0  |58.6| 24.2 |...|
|2020.01.02T09:31:00.000|  270.3|17.1  |59.0| 24.0 |...|

在面板数据上，由于是以时间为索引，标的为列，指标可以方便地进行多标的的滑动窗口函数计算。
首先生成面板数据
```
coin_data = select top 1000000* from coin_minute
coin_data_panel = exec close from a pivot by mtime, symbol
```

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/coin_data_panel.png width=50%></div>

然后通过上面的 factorDoubleEMA 函数来进行面板计算，只需要一行简单的代码。
```
result_panel=factorDoubleEMA(bb)
```
<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/result_panel.png width=50%></div>

## 5.	实时数据处理
面对数字货币瞬息万变的行情，模型及策略都有一定的有效期。能够将投研成果最快的用于生产，将取得先发优势，吃到先发红利。传统的从投研到生产方法，都是先用脚本或者函数，对数据建模分析，有了定性的结论，再投入到回测，最后模拟盘，实盘。建模研究要尽量函数简单，快速迭代。模拟盘和实盘要求性能快速。所以很多研究员使用 python 或者 R 来做建模分析，确定模型后再使用 C++ 或者 go 这类性能比较突出的编程语言来重新实现策略程序。这样两套实现方式，代码开发周期长，结果比对费时费力，从投研到生产的周期很长，在数字货币快速迭代的行情下，无法取得先发优势。

DolphinDB 生产投研一体化的实时数据处理方案，相比传统的 Python + C++ 两套代码的方案，开发上线周期可减少 90% 以上，并且计算越复杂，DolphinDB 的优势越明显。在生产环境中，DolphinDB 提供了实时流计算框架。在流计算框架下，用户在投研阶段封装好的基于批量数据开发的因子函数，可以无缝投入交易和投资方面的生产程序中，这就是通常所说的批流一体。使用流批一体可以加速用户的开发和部署。同时流计算框架还在算法的路径上，做了极致的优化，在具有高效开发的优势的同时，又兼顾了计算的高效性能。

DolphinDB 实时数据处理解决方案的核心部件是流计算引擎和流数据表。流计算引擎用于时间序列处理、横截面处理、窗口处理、表关联、异常检测等操作。流数据表可以看作是一个简化版的消息中间件，或者说是消息中间件中的一个主题（topic），可以往其发布（publish）数据，也可以从其订阅（subscribe）数据。实时数据首先注入流数据表，订阅这个流数据表的流计算引擎会随着实时数据的注入自动完成计算。流计算引擎的输出也可以是流数据表的形式。因此多个计算引擎与流数据表可以跟搭积木一样自由组合，形成流式处理的流水线。图 5-1 是 DolphinDB 的实时数据处理架构图。

<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/streaming.jpg vector.png width=50%>

图 5-1
</div>

### 5.1、实时数据接入
数字货币的技术栈非常复杂，DolphinDB 的提供了多种方式，往流数据表中接入数据。
- 各种语言的 API 向流数据表实时写入数据。
- DolphinDB 的脚本实时向流数据表中写入数据。
- 通过历史数据回放，把历史数据转化为实时数据写入流数据表。
- 第三方消息消息中间件（kafka，zmq，rabbitMq 等）向流数据表实时写入数据。
- 插件方式向流数据表中实时写入数据。
- 流计算引擎计算的结果实时写入流数据表。

基于 DolphinDB 的实时数据处理框架，用户只需要把实时数据写入流数据表，后续的计算全部自动化处理。

### 5.2、实时数据计算
DolphinDB 内置了众多的流计算引擎，只要流数表的数据发布到计算引擎，就可以触发计算，计算规则通过工程化、低代码、参数配置的方式即可完成，相比传统的代码开发，工程周期可缩短 90%。如下是一些常用的流计算引擎及其适合的数字货币的场景：

- 时序聚合引擎（time-series streaming engine），可完成数字货币的时间序列的实时计算，比如实时生成所有周期的 K 线。
- 横截面引擎（cross-sectional streaming engine），可对数字货币完成实时的截面上的计算，比如对所有币种的最新交易量求聚合值。
- 异常检测引擎（anomaly detection streaming engine），可用于数字货币行情及交易的风控或预警。
- 响应式状态引擎（reactive state engine），在数字货币的研究和实盘中，很多计算指标不仅与当前的多个指标有关，而且与多个指标的历史状态相关。响应式状态引擎实现了这种有状态的指标的实时计算，比如计算最近 20 个窗口内的移动相关性，最近 26 个窗口内的移动均值等。
- 流表连接引擎（asof join streaming engine, equal join streaming engine, window join streaming engine, lookup join streaming engine），在数字货币实时计算时，有些情况会用的多路实时数据，比如订单簿和委托一起计算，这个流表的连接引擎即可方便的解决这个问题。

流计算引擎的计算结果可以写入另一个流数据表，一个流数据表也可以被多个计算引擎同时订阅。通过流数据表与流计算引擎的串联或并联，即可使用 DolphinDB 便捷快速高效的解决数字货币复杂的实时计算场景。

### 5.3、实时数据计算结果输出
数字货币行情变化非常迅速，实时计算需要快速输出到生产系统。DophinDB 支持如下几种方式，把实时计算的结果提供给生产系统：
- DolphinDB 提供多种常用编程语言的 API，包括 C++, java, javascript, c#, python, go 等。使用这些语言的程序，都可以调用该语言的 DolphinDB 接口，订阅到 DolphinDB 服务器的实时计算结果。
- 在金融生产环境中，另一种常见的情况，是流数据实时的灌注到消息队列中，如: Zmq，rabbitMq，kafka 等，供下游的其他模块消费。
- 进程间共享内存的方式获取计算结果，这种对接方式可以不经过网络，在内存中直接获取 DlphinDB 计算的结果，非常适合数字货币快速交易、快速风控的需求。
图 5-2 是 DolphinDB 对接生产的架构图：
<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/streamCalc.png vector.png width=50%>

图 5-2
</div>

### 5.4、数据回放
行情仿真在数字货币数据研究或行情分发上有较多的使用。在 DolphinDB 中，用户可将历史数据逐行读取，并按照时间顺序以 “实时数据” 的方式导入流表中，实现 “数据回放”。数据回放的特性如下：

- 将本地磁盘数据或分布式数据库转换成流数据。
- 支持多个数据表同时回放，并保持时间线同步。
- 自定义 SQL 回放，通过 SQL 语句可以实现任意位置的数据回放。
- 支持回放速率自定义。

通过数据回放，就能实现对同一批数据的反复实时研究，同时也可以随时仿真实时行情做推送。

### 5.5、批流一体
如这章和上一章的介绍，DolphinDB 拥有非常快速的历史数据分析计算框架和开发便捷的实时数据分析计算框架。批流一体的功能把两者整合为一体。批流一体是指将研发环境中对历史数据建模分析得到的因子或表达式直接应用于生产环境的实时数据中，并保证流式计算的结果和批量计算完全一致，二者使用同一批代码，被称之为 “批流一体”。数字货币变化非常迅速，能否将历史数据研究的成果尽快用于生产是非常重要的。流批一体的好处在于：研发环境和生产环境共用一套代码，代码在研发结束后就可以直接投入到生产环境，节约了产品开发周期，赢得了先发优势。同时，无需维护两套代码，节约了开发成本，还规避了两套体系可能带来的批计算与流计算结果不一致的问题。比传统的用 python 或者 R 来做建模分析，确定模型后再使用 C++ 或者 go 这类性能比较突出的编程语言来重新实现策略程序的方式，效率可提升 90%。



## 6. 高可用方案

- 面对数字货币 7 * 24小时交易的场景，需要系统有长期不间断工作能力。DolphinDB提供了集群高可用机制(RAFT协议)避免控制节点的单点故障，提供多副本机制保证数据的高可用性。并且考虑到没有像股票市场有盘后补偿的时间，DolphinDB在数据入库时支持分布式事务，保障数据写入分布式数据库时保证数据多副本的一致性。
- 
- 图 6-1 是 DolphinDB 的高可用架构图：
<div align=center><img src=images/DolphinDB_Solutions_for_Cryptocurrency/highAvailability.png width=50%>

图 6 -1
</div>

### 6.1、高可用概述
DolphinDB 提供了分区数据、元数据、流数据和客户端的高可用方案，使得数据库节点发生故障或宕机时，数据库依然可以正常运作，保证业务不会中断，以满足数字货币领域 24 小时不中断提供服务的需求。DolphinDB 流数据的高可用还包括 Broker 的高可用、生产者高可用和消费者的高可用。流数据高可用和元数据高可用，使用 RAFT 协议实现；分区数据高可用使用多副本方式实现；客户端高可用使用各个节点都可以可供服务的对等架构实现。
### 6.2、元数据高可用
数据存储时会产生元数据，元数据保存了数据库的分区信息，包括每个分区大小，存储位置、数据版本等，例如每个数据块存储在哪些数据节点上的哪个位置等信息。DolphinDB 的元数据存储在控制节点上，可以在一个集群中部署多个控制节点，通过元数据冗余来保证元数据服务不中断。一个集群中的所有控制节点组成一个 Raft 组，Raft 组中只有一个 Leader，其他都是 Follower。Leader 和 Follower 上的元数据具有强一致性。数据节点只能和 Leader 进行交互。如果当前 Leader 宕机，系统会立即选举出新的 Leader 来提供元数据服务。Raft 组能够容忍小于半数的控制节点宕机，只要宕机的控制节点少于半数，集群仍然可以提供服务。
### 6.3、数据高可用
分区数据高可用指的是实际的存储数据，可以保留多个副本。为了保证数据的安全和高可用，DolphinDB 支持在不同的服务器上存储多个数据副本，并且采用两阶段提交协议实现数据副本之间以及数据和元数据之间的强一致性。即使一台机器上的数据损坏，也可以通过访问其他机器上的副本数据来保证数据服务不中断；同时，不同节点的不同副本在同一时刻可保持数据的完全一致，即在同一时间向任何节点发出相同的查询 B
### 6.4、流数据高可用
为满足流数据服务不中断的需求，DolphinDB 提供了流数据的高可用功能。
DolphinDB 流数据高可用功能采用了基于 Raft 协议的高可用多副本架构。相同流数据的副本存储在 Raft 组内不同的数据节点上，Raft 协议用来维护多个副本的一致性。Raft 组具有自动恢复的性质，当少数半数的节点失效的时候不影响 Raft 组的正常工作。

一个发布订阅流数据系统包含三个角色：Publisher（生产者），Broker 和 Subscriber（消费者）。在 DolphinDB 流数据框架中，Broker 由 DolphinDB 的数据节点担任，Publisher 和 Subscriber 由 DolphinDB 数据节点或第三方 API 程序担任。DolphinDB 流数据的高可用包括 Broker 的高可用、生产者和消费者的高可用，并具有以下特性：

- 每个节点上可以定义一个或多个 Raft 组，一个 Raft 组可以接纳多个流数据表
- 一个流数据表创建时可指定一个 Raft 组，表明该表为高可用的流数据表。如果没有指定 Raft 组，就是普通的流数据表
- Publisher 向 Leader 写入数据。若写入失败或者收到非 Leader 异常，就自动切换到新的 Leader 节点写入。发布端 Leader 节点宕机，新选举出的 Leader 会重新连接，写入数据
- Subscriber 从 Leader 订阅流数据。因为网络原因，或 Leader 重新选举后，从 Leader 变换为 Follower 时，Broker 会主动断开这个 Raft 组内所有的流表对应的订阅端连接。Subscriber 连接被断开，或者收到新的 Leader 选出的通知后，会自动向新的 Leader 发起订阅。当订阅端 Leader 节点宕机时，同一个 Raft 组内的其它节点会推选出新的 Leader 重新订阅

### 6.5、客户端高可用
使用 API 与 DolphinDB server 的数据节点进行交互时，如果连接的数据节点宕机，API 会尝试重连，若重连失败会自动切换到其他可用的数据节点。该操作对用户是完全透明的。目前 Java, C#, C++ 和 Python API 支持高可用。

## 7.	小结
DolphinDB 拥有一套完整的高可用体系架构，其核心为一个分布式集群系统，内置分布式文件系统、分布式计算、分布式数据库、流计算引擎和脚本语言模块。各个模块相互独立，又紧密配合，可以一站式提供分布式文件系统、分布式计算、内存数据库、消息队列、流计算等功能。数字货币的数据存储查询，数据清洗，因子开发，策略研究，流数据计算等业务都可以一站式的在 DolphinDB 中得到快速高效解决，极大的减少大数据管理和分析系统的技术栈、降低了硬件、人员、开发、维护等综合成本。