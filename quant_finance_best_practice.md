# 量化金融数据库设计最佳实践

## 1. 数据库集群的配置

### 1.1 硬件的配置

磁盘I/O对于大规模数据处理性能的提升非常重要。建议SSD和HDD都配置。配一块小容量SSD盘存储元数据；同样的数据存储量的要求，优先考虑采购多个小容量HDD磁盘以充分利用并行读写，提高吞吐量。具体建议SSD 500GB或以上，如果考虑用于流数据处理，对时延非常敏感，建议使用企业级SSD。HDD建议8~16个1.2TB 10K RPM，用于历史数据落盘保存。金融数据压缩比约为25%（即压缩后为原始数据的25%），可以根据数据量乘以压缩比来评估所需的磁盘容量。

由于金融行业的数据分析工作种类繁多且复杂，在预算足够的前提下建议高配内存。充足的内存可保证数据清洗和分析的高效率。推荐配置512GB内存。

DolphinDB对CPU的要求主要取决于分析计算涉及的数据量和复杂度。分析计算涉及的分区数越多或者分析越复杂，对CPU核数要求越高。

建议节点间内网配置万兆网络。DolphinDB的集群节点之间基于网络TCP协议传输数据，集群内的高速网络能提高大量数据查询和聚合的速度。

### 1.2 单节点 vs 集群

对相当一部分的量化金融工作，可以将DolphinDB部署在一台24核CPU，512GB内存的服务器，采用单节点模式。

若需要高可用或负载均衡，需要采用集群模式。

若确保服务不间断，需要高可用，可配置2-3台服务器。

若系统使用人数多，数据量极大，需要考虑负载均衡。

## 2. DolphinDB的工作原理


### 2.1 DolphinDB的分区机制



### 2.2 分布式Query的实现


### 2.3 DolphinDB的计算引擎

DolphinDB的分区数据库拥有一种分区机制(partitioning scheme)。一个数据库内的多个事实表(fact table)共享这种分区机制，而且同一个分区的多个子表(tablet chunk)数据存储在同一个节点上，所以多个事实表（譬如quotes和trades）的join效率非常高。DolphinDB作为一个列式分析型数据库，宽表是最常见的情景。一个应用可能只会用到宽表中的某几个列，但是其余没有用到的列不会影响数据库性能。因此可以把采集频率相同的数据放到一个宽表中，以简化数据库的设计。

除了分布式的事实表，DolphinDB还提供了不分区的维度表(dimension table)。维度表通常用于存储reference data。这类数据的数据量通常不会随着时间的积累而增长，而且数据内容变化较小。维度表可与采用任何分区机制的事实表关联。DolphinDB还提供了基于内存和磁盘的流数据表，用于处理实时或者基于历史数据仿真的流数据。实时流数据表既可用于实时数据的快速查询，也可用于是计算和监控，譬如K线计算和风险控制。仿真的流数据表可用于策略回测。

DolphinDB不仅是一个分布式数据库，更是一个强大的计算引擎。DolphinDB提供了多种内存表以辅助计算和缓存。

## 3. 行情数据(market data)库的设计

### 3.1 行情数据库的分区设计

行情数据是量化金融中量级最大的数据类别。在中国的证券市场，累积的历史数据在20~40T左右，每日新增的数据在20~40G左右。传统的关系型数据库处理这样的数据量级的性能非常低下。即使分库分表，效果也不理想。DolphinDB的分区机制可以轻松应对几百TB甚至PB级别的数据量。

为保证最佳性能，尽量将数据均匀分区，且将每个表的每个分区的数据量控制在压缩前100M左右。这是因为DolphinDB并不提供行级的索引，而是将分区作为数据库的物理索引，因此每个分区的数据量不宜过大。

行情数据通常可用时间和产品标识两个维度来进行分区：

(1) 时间维度大部分情况下可以选择按天进行值分区。如果时间跨度不是很长，而每天的数据量又非常大，也可以考虑按照小时进行分区，为此DolphinDB提供了DATEHOUR这种数据类型。设计分区机制时要考虑常用的应用场景。譬如说每次的请求都是对单一股票进行查询或聚合计算，而且跨越的时间比较长，可能几个月甚至一年，那么时间维度上按月分区不失为一种好的做法。

(2) 产品标识维度的分区可采用哈希、范围、值、列表等多种方法。如果每个产品在固定时间内的数据量比较均匀，可采用哈希或范围分区。例如中国的期货与股票市场以固定频率发布报价和交易的快照，因此每个市场内不同产品的数据量基本一致。美国金融市场的行情数据分布则完全不同，不同股票的tick级别数据量差异非常大。这种情境下，可选择范围分区，以一天或多天的数据为样本，将产品标识划分成多个范围，使得每一个范围内的产品的数据总量比较均衡。如果产品个数比较少，譬如期货的品种比较少，也可以考虑用值分区。

行情数据包括每日数据(end of day data)、Level 1、Level 2、Level 3等不同级别的数据。不同级别的数据，数据量差异比较大。所以建议采用不同分区机制的数据库来存储这些数据。

DolphinDB中的多个分区维度并不是层级关系，而是平级的组合关系。如果时间维度有n个分区，产品维度有m个分区，最多可能有n x m个分区。

### 3.2 不同资产的数据库设计

股票、期货和期权是金融市场中最常见的资产类别。我们建议使用不同的数据库来存储不同资产的数据。首先，时间维度上，单位时间内不同资产的数据量差别可能很大。其次，产品标识这个维度上，不同资产的产品数量差别较大，很难用同一种方法进行分区。

不同资产采用不同数据库的一个潜在问题是如何实现不同资产数据之间的快速join。譬如在处理股票期权数据时，有时需要找到某些期权对应的股票的行情数据。可以先将对应股票的行情数据载入内存表，然后再将该内存表与期权的事实表进行关联。

### 3.3 K线数据库的设计

K线数据或相关的signal数据都是基于高精度的行情数据降低时间精度产生的数据。通常，我们会生成不同频率的K线，譬如1分钟、5分钟、30分钟等等。这些不同频率的K线数据，因为数据量不是太大，建议存储在同一个分区表中，可以增加一个字段frequency来区分不同的时间窗口。K线表通常也按照日期和产品标识两个维度来分区，分区的粒度由数据量决定。以中国股票市场的分钟级K线为例，3000个股票每天产生约240个数据点，总共约72万个数据点。建议时间维度按月进行分区，产品的维度按范围或哈希分成15个分区。这样每个分区的数据量在100万行左右。这样的分区方法，既可在较长时间范围内（1个月或1年）快速查找某一个股票的数据，也可应对查找一天内全部股票的数据这样的任务。

### 3.4 行情数据的实时计算

DolphinDB内置了流数据处理引擎。行情数据可以发布到流数据表，并被DolphinDB的数据节点或第三方的API（Python, Java, C++, Go等）订阅。订阅行情数据后，K线计算与风险控制等问题都可以快速实现。流数据的计算既可使用DolphinDB内置的计算引擎（时间序列聚合引擎，横截面聚合引擎等），也可使用DolphinDB脚本或第三方API自定义消息处理函数。当使用DolphinDB脚本处理复杂的计算逻辑时，譬如计算期权的Greeks，可以启用即时编译(JIT)以提升计算速度。

[DolphinDB流数据教程](./streaming_tutorial.md)

[DolphinDB时序聚合引擎](./stream_aggregator.md)

[DolphinDB K线生成指南](./OHLC.md)

[DolphinDB即时编译(JIT)教程](./jit.md)

## 4. 周期性研究数据库的设计

量化金融的研究需要各种类型的数据。除了数据量最大的行情数据，其它常用类型包括：（1）宏观经济数据，（2）上市公司的财务数据，（3）卖方分析师的预测数据，（4）上市公司的各类事件数据（除权、分割、分红等）。数据通常通常都会有时间戳（事件本身的时间戳和数据发布的时间戳）。这类数据相对于行情数据，数据量非常小，可以加载全部数据到内存中进行复杂的处理。

这类数据库的设计相对简单。如果数据量比较小，譬如宏观数据，可存放到不分区的维度表。如果数据量比较大，可以考虑按照时间维度进行分区。周期性数据通常包含月度和季度数据，按照年度进行分区是一个比较可行的做法。如前所述，每一条记录通常包含两个时间戳，事件本身的时间和数据发布的时间。同一个事件有可能发布多次，通常后续的发布是对之前发布的数据的修正。因此，按时间进行维度分区时，一般选择事件本身的时间戳。为了保证研究结果没有look-ahead bias，一般需要保存所有数据版本。用户查询时，如果只需要最后一个版本，可使用SQL中的context by子句。

DolphinDB作为一个分布式的时序数据库，不支持单行数据的删除和更新操作，因此保留同一事件的所有版本对DolphinDB最为方便和高效。如果只在数据库中保留最后一个版本，需要以分区为单位，将分区数据加载到内存并更新，删除原有的分区数据，再将内存表数据写入到分区。

周期性研究数据存在纷繁复杂的数据种类以及数据来源。如何及时将外部数据源同步到DolphinDB数据库是一项非常重要的工作。我们可以借助一些数据同步中间件，根据数据发布的时间来完成数据同步。

## 5. 参考数据(reference data)库的设计

数据仓库建模的雪花模型通常包括事实表和维度表。维度表的数据通常是事实表中的某些字段的外键。量化金融的数据库建模也会包含多种维度数据，例如证券产品（如股票）的介绍(security master)，参与交易的机构(counterparty)，交易货币(currency)，交易消息(message)等。这一类数据在金融领域通常称为reference data。这一类数据数量非常有限，不会随着时间的变化线性增长。维度表的变化一般不会很频繁。

DolphinDB提供了维度表(dimension table)来存储reference data。维度表是不分区的，但是数据的写入和分区表无异。DolphinDB会自动在各个节点上缓存维度表，以提升查询和关联的性能。维度表可与任何分布式表，维度表以及内存表进行关联。


## 6. DFS数据库分区脚本示例

### 6.1 中国股票 level 2 行情数据库分区脚本示范

中国股票市场每3秒种更新一条 level 2 的行情数据，一般包括股票代码、日期、时间、交易量、交易价格、交易次数，买方与卖方的10档报价与量、其它信息等数据，总共50-70列左右。本例中所用数据为上海证券交易所A股股票2020年6月的 level 2 数据，每天的数据是一个约为2GB的CSV文件，均存于同一个文件夹下。遵循每个表每个分区中的数据压缩前为100MB左右的原则，可将数据库设计为复合分区。按天进行值分区，按照股票代码分为20个HASH分区。

具体建库脚本如下：
```
dbDate = database("", VALUE, 2020.01.01..2020.12.31)
dbID=database("", HASH, [SYMBOL, 20])
db = database("dfs://level2", COMPO, [dbDate, dbID])

myDir="C:/DolphinDB/Data/Level2text/"

def importFiles(myDir, db){
    myFiles = exec filename from files(myDir)
    for(f in myFiles){
        loadTextEx(db,`quotes,`date`symbol, myDir + f)
    }
}
importFiles(myDir, db)
```

原始的CSV数据文件中有时会包含一些无关的数据。可在加载数据前进行过滤，只将所需数据载入数据库。以下脚本仅将symbol在600000与700000之间的上海A股股票数据载入数据库 dfs://level2_2 中的 quotes 表 ：
```
dbDate = database("", VALUE, 2020.01.01..2020.12.31)
dbID=database("", HASH, [SYMBOL, 25])
db = database("dfs://level2_2", COMPO, [dbDate, dbID])

schema = extractTextSchema(myDir+"20200601.csv")
modelTable = table(1:0, schema.name, schema.type)
quotes=db.createPartitionedTable(modelTable,`quotes, `date`symbol)

def filterImport(inputTable, mutable updateTable){
	temp=select * from inputTable where symbol>="600000", symbol<"700000"
	append!(updateTable, temp)
}
def importFiles(myDir, db, mutable updateTable){
    myFiles = exec filename from files(myDir)
    for(f in myFiles){
        ds=textChunkDS(myDir + f,300)
		mr(ds=ds, mapFunc=filterImport{,updateTable}, parallel=false)
    }
}
importFiles(myDir, db, quotes)
```
以上脚本使用了`textChunkDS`函数，将文本文件分为多个300MB的数据源，再使用Map-Reduce函数`mr`逐一对数据源进行过滤，并写入数据库。



### 6.2 因子数据库分区脚本示范

因子数据库可选用多值模型或单值模型。多值模型中，每个因子为单独的一列。单值模型中，所有因子均存于同一列。

相对于单值模型，多值模型的好处在于查找速度快。但是，在添加新的因子时，只能对未来数据添加（使用`addColumn`命令），无法对已有数据添加。

### 6.2.1 分钟级因子数据库分区脚本示范

假设中国股市3000只股票，每只股票每分钟产生100个因子。

单值模型下，因子表共有4列：股票代码、时刻、因子代码、因子值。对应的数据类型分别为SYMBOL, DATETIME, INT, FLOAT，每行为16字节，每天共有3000*100*4*60行，压缩前数据量约为1.1GB。

多值模型下，因子表可有102列：股票代码、时刻，以及100列因子。每行为408字节，每天共有3000*4*60行，压缩前数据量约为0.3GB。虽然单值模型于多值模型的数据量压缩前有几倍的差别，压缩后存于磁盘的空间差别很小，原因在于单值模型中除因子值之外的数据有极多重复，压缩效率非常高。

遵循每个表每个分区中的数据压缩前为100MB左右的原则，可将数据库设计为复合分区。按天进行值分区，按照股票代码进行HASH分区。单值模型可分为10个HASH分区；多值模型可分为3个HASH分区。

日级因子数据一般为每日交易结束后计算一次，然后将计算结果存入数据库。以下脚本中，将内存中数据表 newData 添加到因子数据库 dfs://factors_minute 中。
```
dbDate = database("", VALUE, 2020.01.01..2020.12.31)
dbID=database("", HASH, [SYMBOL, 10])
db = database("dfs://factors_minute", COMPO, [dbDate, dbID])
factors=db.createPartitionedTable(newData,`factors, `date`symbol)
append!(factors, newData)
```
请注意，该数据库设计中的VALUE分区为每天一个分区，但是新增数据中对应的分区列的数据类型为DATETIME，此时系统会自动按照DATETIME中的日期信息分配分区，用户无需将DATETIME转换为DATE。

#### 6.2.2 日级因子

假设中国股市3000只股票，每只股票每天产生100个因子。

单值模型下，每个月数据压缩前约为100MB。多值模型下，每个月数据压缩前约为25MB。

若经常需要查询某天所有股票的所有因子，可将数据按月进行范围分区，每4个月划为一个分区。



